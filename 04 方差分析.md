[toc]

# 01 方差分析

主要研究分类变量作为自变量时，对因变量的影响是否是显著的。

## 相关概念

组间因子，组内因子：不同因子是否仅被分到一个组别。

自变量，因变量。

均衡设计，非均衡设计：每种方案下观测数是否相等。

单因素方差分析，包括：单因素组间方差分析（如对照试验），单因素组内方差分析（如多疗程效果检测）。

重复测量方差分析。

组效应，交互效应

当设计包含两个甚至更多的因子时，便是**因素方差分析设计**，比如两因子时称作**双因素方差分析**，三因子时称作三因素方差分析，以此类推。若因子设计包括组内和组间因子，又称作**混合模型方差分析**。

混淆因素，干扰因素。

**协变量**：在实验的设计中，协变量是一个独立变量（解释变量），不为实验者所操纵，但仍影响实验结果。

**协方差分析**亦称“共变量（数）分析”。方差分析的引申和扩大。基本原理是将线性回归与方差分析结合起来，调整各组平均数和 F 检验的实验误差项，检验两个或多个调整平均数有无显著差异，以便控制在实验中影响实验效应（因变量）而无法人为控制的协变量（与因变量有密切回归关系的变量）在方差分析中的影响。

当因变量不止一个时，设计被称作**多元方差分析**（MANOVA）， 若协变量也存在， 那么就叫**多元协方差分析**

## 单因素方差分析

### 推导

问题中涉及一个因素$A$，有$k$个水平，分别在$n_i$个小组，$n_1 + n_2 + ... n_k = n$. $Y_{ij}$记第$i$个水平的第$j$个观察值。模型为
$$
Y_{ij} = a_i + e_{ij},  j = 1,...,n_i, i = 1,...,k\qquad(2.1)
$$
$a_i$表示水平$i$的理论平均值，称为水平$i$的效应。$e_{ij}$是随机误差。并且我们假定：
$$
E(e_{ij})=0, 0<Var(e_{ij})={\sigma}^2<\infty,一切e_{ij}独立同分布\qquad(2.2)
$$
因素$A$的各水平的高低优劣，取决于其理论平均$a_{i}$的大小。故对模型(2.1)，我们头一个关心的事情，就是诸$a_{i}$是否全相同。 如果是，则表示因素$A$对所考察的指标$Y$其实无影响．这时我们就说因素A的效应不显著，否则就说它显著。当然，在实际应用中，所谓“显著”，是指诸$a_{i}$之间的差异要大到一定的程度．这个 “一定的程度”，是从其实用上的意义着眼，而“统计显著性”，则是与随机误差相比而言．这点在下文的讨论中会有所体现．我们把所要检验的假设写为：
$$
H_0:a_1=a_2=\cdots=a_k \qquad (2.3)
$$
为检验该假设，我们需要分析，为什么各个$Y_{ij}$会有差异？从模型(2.1)来看，无非两个原因：一是各$a_{i}$可能有差异．例如，若 $a_1>a_2$, 这就使$Y_{1j}$倾向于大于$Y_{2j}$；二是随机误差的存在。这一分析启发了如下的想法：找一个衡量全部$y_{ij}$的变异的量：
$$
SS= \sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y} \right )^2, \qquad \bar{Y}=\sum_{i=1}^{k}\sum_{j=1}^{n_i}Y_{ij}/n \qquad (2.4)
$$
$SS$愈大，表示$Y_{ij}$之间的差异越大。

接下来，把$SS$分为两部分，一部分表示随机误差的影响，记为$SS_e$；另一部分表示因素$A$的各水平理论平均值$a_i$不同带来的影响，记为$SS_A$。

关于$SS_e$，先固定一个$i$，此时对应的所有观测值$Y_{i1},Y_{i2},\cdots,Y_{in}$，他们之间的差异与每个水平的理论平均值不等无关，而是取决于随机误差，反映这些观察值差异程度的量是$\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y_i} \right )^2$，其中
$$
\bar{Y_i}=(Y_{i1}+Y_{i2}+\cdots+Y_{in})/n_i,\quad i=1, 2,\cdots,n \qquad (2.5)
$$
$\bar{Y_i}$可以视为对$a_i$的估计。把上述平方和做累加得：
$$
SS_e=\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y_i} \right )^2 \qquad (2.6)
$$
可求得$SS_A$:
$$
\begin{align}
SS_A &= SS-SS_e \\ 
&=\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y} \right )^2-\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y_i} \right )^2 \\
&=\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( (Y_{ij}-\bar{Y_i})-(\bar{Y_i}-\bar{Y}) \right )^2-\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y_i} \right )^2 \\
&=\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( (Y_{ij}-\bar{Y_i})^2-2(Y_{ij}-\bar{Y_i})(\bar{Y_i}-\bar{Y})+(\bar{Y_i}-\bar{Y})^2 \right )-\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y_i} \right )^2 \\
&=\sum_{i=1}^{k}\sum_{j=1}^{n_i}(Y_{ij}-\bar{Y_i})^2 - 2\sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( (Y_{ij}-\bar{Y_i})(\bar{Y_i}-\bar{Y}) \right )
+ \sum_{i=1}^{k}\sum_{j=1}^{n_i}(\bar{Y_i}-\bar{Y})^2 - \sum_{i=1}^{k}\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y_i} \right )^2 \\
&= \sum_{i=1}^{k}\sum_{j=1}^{n_i}(\bar{Y_i}-\bar{Y})^2 - 2\sum_{i=1}^{k}\left ( (\bar{Y_i}-\bar{Y})\sum_{j=1}^{n_i}(Y_{ij}-\bar{Y_i}) \right ) \quad (ps:\sum_{j=1}^{n_i}(Y_{ij}-\bar{Y_i})=0) \\
&= \sum_{i=1}^{k}n_i(\bar{Y_i}-\bar{Y})^2 \qquad (2.7)
\end{align}
$$
因为$\bar{Y_i}$可以视为对$a_i$的估计，$a_i$的差异越大，$\bar{Y_i}$之间的差异也越大，所以$SS_A$可以用来衡量不同水平之间的差异程度。

在统计学上，通常称$SS$为**总平方和**，$SS_A$为**因素$A$的平方和**，$SS_e$为**误差平方和**，分解式$SS=SS_A+SS_e$为该模型的**方差分析**。

基于上面的分析，我们可以得到假设（5.3）的一个检验方法：当比值$SS_A/SS_e$大于某一给定界限时，否定$H_0$，不然就接受$H_0$。为了构造$F$分布的检验统计量，我们假定随机误差$e_{ij}$满足正态分布$N(0, \sigma^2)$，同时我们也假定观察值$Y_{ij}$符合正态分布，此时，记
$$
MS_A = SS_A/(k-1), \quad MS_e = SS_e/(n-k) \qquad (2.8)
$$
当$H_0$成立时，有：
$$
MS_A / MS_e \sim F_{k-1, n-k} \qquad (2.9)
$$
据（5.9），在给定显著性水平$\alpha$时，即得（5.3）的假设$H_0$的检验如下：
$$
当MS_A / MS_e \leqslant  F_{k-1, n-k}(\alpha)时，接受H_0，不然就拒绝H_0 \qquad (2.10)
$$
$MS_A$和$MS_e$分别被称为**因素$A$和随机误差的平均平方和**。被除数$k-1$和$n-k$，分别称为这两个平方和的**自由度**。$MS_e$的自由度为什么是$n-k$呢？因为平方和$\sum_{j=1}^{n_i}\left ( Y_{ij}-\bar{Y_i} \right )^2$的自由度为$n_i-1$，故对$i$求和，$SS_e$的自由度就是$n-k$。那么，$MS_A$的自由度为什么是$k-1$呢？因为一共有$k$个平均值$a_1,\cdots,a_k$等$k-1$个，故自由度为$k-1$，两者自由度之和为$n-1$，恰好是总平方和的自由度。

到这里，我们可以做出方差分析表如表2-1

**2-1 单因素方差分析的方差分析表**

| 项目 | $SS$   | 自由度 | $MS$   | $F$比         | 显著性      |
| ---- | ------ | ------ | ------ | ------------- | ----------- |
| $A$  | $SS_A$ | $k-1$  | $MS_A$ | $MS_A / MS_e$ | *, **, 或无 |
| 误差 | $SS_e$ | $n-k$  | $MS_e$ |               |             |
| 总和 | $SS$   | $n-1$  |        |               |             |

在上表中，对于显著性一栏，一般来说，我们把算出的$F$比，即$MS_A / MS_e$，与$F_{k-1, n-k}(0.05)=c_1$和$F_{k-1, n-k}(0.01)=c_2$比较。若$MS_A / MS_e>c_2$，用**表示，表明A因素的效应是高度显著的，即在$\alpha=0.01$的显著性水平下，拒绝原假设（5.3）。同理，$c_2<MS_A / MS_e<c_1$用$\ast $表示，$MS_A / MS_e>c_1$时不显著。

### 代码实现

参考博客https://www.cnblogs.com/jin-liang/p/9852321.html

```python
from scipy import stats
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.multicomp import pairwise_tukeyhsd
import warnings
warnings.filterwarnings("ignore")

import itertools

# 数据生成
df2=pd.DataFrame()
df2['group']=list(itertools.repeat(-1.,9))+ list(itertools.repeat(0.,9))+list(itertools.repeat(1.,9))

df2['noise_A']=0.0
for i in data['A'].unique():
    df2.loc[df2['group']==i,'noise_A']=data.loc[data['A']==i,['1','2','3']].values.flatten()
    
df2['noise_B']=0.0
for i in data['B'].unique():
    df2.loc[df2['group']==i,'noise_B']=data.loc[data['B']==i,['1','2','3']].values.flatten()  
    
df2['noise_C']=0.0
for i in data['C'].unique():
    df2.loc[df2['group']==i,'noise_C']=data.loc[data['C']==i,['1','2','3']].values.flatten()  
    
df2

# 数据分析
# for A
anova_reA= anova_lm(ols('noise_A~C(group)',data=df2[['group','noise_A']]).fit())
print(anova_reA)
#B
anova_reB= anova_lm(ols('noise_B~C(group)',data=df2[['group','noise_B']]).fit())
print(anova_reB)
#C
anova_reC= anova_lm(ols('noise_C~C(group)',data=df2[['group','noise_C']]).fit())
print(anova_reC)
```

### 检验假设条件

#### 正态性检验

第一，在建立模型时，我们假设因变量是服从正态分布的，需要进行正态性检验。

正态性检验的方法有两种，一是通过QQ图进行检验。

其他方法

* K-S test

  统计学里, Kolmogorov–Smirnov 检验(亦称：K–S 检验)是用来检验数据是否符合某种分布的一种非参数检验。其原假设$H_0$:两个数据分布一致或者数据符合理论分布。在R语言里，我们可以使用`ks.test(x, pnorm)`进行正态性检验，若结果中的p值大于0.05，则数据符合正态分布。

* Anderson–Darling test

  Anderson–Darling检验是一种用来检验给定的样本是否来自于某个确定的概率分布的统计检验方法。在R语言中，我们可以从**nortest包**中的`ad.test()`进行检验。若结果中的p值大于0.05，则数据符合正态分布。

* Shapiro-Wilk test

  Shapiro-Wilk检验在小样本情况下，是很普通的正态性检验方法，`Shapiro.test()`在默认安装的**stats**包中。原假设$H_0$: 数据符合正态分布。

* Lilliefor test

  Lilliefor test是基于Kolmogorov–Smirnov test的一种正态性检验。原假设$H_0$: 数据符合正态分布，`lillie.test()`也在**nortest包**中。

#### 方差齐性检验

因为方差分析的实质是检验多个水平的均值是否有显著差异，如果各个水平的观察值方差差异太大，只检验均值之间的差异就没有意义了，所以要进行方差齐性检验。

## 双因素方差分析

### 推导

我们设有两个因素$A, B$，分别有$k, l$个水平，$A$的水平$i$与$B$的水平$j$的组合记为$(i,j)$，其试验结果记为 $Y_{ij}, i = 1, · · ·, k,j = 1,…, l$．统计模型定为
$$
Y_{ij} = \mu + a_i + b_j + e_{ij}，i= 1, · · ·, k,j = 1,· · ·, l\qquad (3.1)
$$
为解释这模型，首先把右边分成两部分：$e_{ij}$为随机误差，它包含了未加控制的因素($A,B$以外的因素）及大量随机因素的影响．假定
$$
E(e_{ij})=0, 0<Var(e_{ij})={\sigma}^2<\infty,一切e_{ij}独立同分布\qquad(3.2)
$$
另一部分$\mu + a_i + b_j$，它显示水平组合$(i,j)$的平均效应．它可以又分解为三部分：$\mu$是总平均（一切水平组合效应的平均），是一个基准．$a_i$表示由$A$的水平$i$带来的增加部分，称为因素$A$的水平$i$的效应．$b_j$有类似的解释．调整$\mu$的值，我们可以补充要求：
$$
a_1+···+a_k=0,b_1+···+b_l=0 \qquad (3.3)
$$
如果$(3.3)$式不成立，则分别把$\mu$换为 $\mu + \bar{a}+\bar{b}$，$a_i$换为$a_i-\bar{a}$，$b_j$换为$b_j-\bar{b}$，则$(3.1)$式不变，而$(3.3)$式成立。

约束条件$(3.3)$给了$a_i，b_j$的意义一种更清晰的解释：$a_i>0$ 表示A的水平$i$的效应在$A$的全部水平的平均效应之上，$a_i<0$ 则相反。另外，这个约束条件也给了$\mu，a_i,b_j$的 一个适当的估计法：把$Y_{ij}$对一切$i,j$相加．注意到$(3.3)$，有
$$
\sum_{i=1}^{k}\sum_{j=1}^{l}Y_{ij}= kl\mu+\sum_{i=1}^{k}\sum_{j=1}^{l}e_{ij} \qquad (3.4)
$$
由$(3.2)$得，
$$
\bar{Y}=\sum_{i=1}^{k}\sum_{j=1}^{l}Y_{ij}/kl \qquad (3.5)
$$
是$\mu$的一个无偏估计。其次，有
$$
\sum_{j=1}^{l}Y_{ij}=l\mu+la+\sum_{j=1}^{l}e_{ij} \qquad (3.6)
$$
于是，记
$$
\bar{Y_i}=\sum_{j=1}^{l}Y_{ij}/l, \quad \bar{Y_j}=\sum_{i=1}^{k}Y_{ij}/k \qquad (3.7)
$$
由$(3.7)$知，$\bar{Y_j}$为$\mu+a_i$的一个无偏估计。于是得到$a_i$的一个无偏估计为
$$
\hat{a_i}=\bar{Y_i}-\bar{Y}, i=1,\cdots,k \qquad(3.8)
$$
同理，
$$
\hat{b_j}=\bar{Y_j}-\bar{Y}, j=1,\cdots,l \qquad(3.9)
$$
$\hat{a_i},\hat{b_j}$适合约束条件$(3.3)$。

下面进行方差分析，要设法把总平方和
$$
SS=\sum_{i=1}^{k}\sum_{j=1}^{l}(Y_{ij}-\bar{Y})^2
$$
分解为三部分：$SS_A,SS_B,SS_e$，分别表示因素$A,B$和随机误差的影响。这种分解的主要目的是假设检验：
$$
H_{0A}:a_1=\cdots=a_k=0 \qquad(3.10)
$$
和
$$
H_{0B}:b_1=\cdots=b_k=0 \qquad(3.11)
$$
$H_0A$成立表示因素$A$对指标其实无影响。在实际问题中，绝对无影响的场合少见，但如影响甚小以致被随机误差所掩盖时，这种影响事实上等于没有。因此，拿$SS_A$和$SS_e$的比作为检验统计量正符合这一想法．

接下来讲一下方差分解的小技巧：
$$
Y_{ij}-\bar{Y}=(\bar{Y_i}-\bar{Y}) + (\bar{Y_j}-\bar{Y})+(Y_{ij}-\bar{Y_i}-\bar{Y_j}+\bar{Y})
$$
两边平方，对$i,j$求和，结合约束条件(3.3)，注意到
$$
\sum_{i=1}^{k}(\bar{Y_{i}}-\bar{Y})=0， 
\sum_{j=1}^{l}(\bar{Y_{j}}-\bar{Y})=0，
$$

$$
\sum_{i=1}^{k}(Y_{ij}-\bar{Y_i}-\bar{Y_j}+\bar{Y})=\sum_{j=1}^{l}(Y_{ij}-\bar{Y_i}-\bar{Y_j}+\bar{Y})=0
$$

即知所有交叉积之和皆为0，而得到
$$
\begin{align}
SS&=l\sum_{i=1}^{k}(\bar{Y_{i}}-\bar{Y})^2+k\sum_{j=1}^{l}(\bar{Y_{j}}-\bar{Y})^2+\sum_{i=1}^{k}\sum_{j=1}^{l}(Y_{ij}-\bar{Y_i}-\bar{Y_j}+\bar{Y})^2 \\
&=SS_A + SS_B + SS_e \qquad(3.12)

\end{align}
$$
第一个平方和可以作为因素$A$的影响的衡量，从前述$\bar{Y_{i}}-\bar{Y}$作为 $a_i$的估计可以理解第二个平方和同理。至于第三个平方和可作为随机误差的影响这一点， 直接看不甚明显。可以从两个角度去理解：在$SS$中去掉$SS_A$ 和$SS_B$后，剩余下的再没有其他系统性因素的影响，故只能作为$SS_e$。另外，由模型$(3.1)$及约束条件$(3.3)$，易知
$$
\begin{align}
Y_{ij}-\bar{Y_i}-\bar{Y_j}+\bar{Y} &= (\mu + a_i + b_j + e_{ij}) - (\mu + a_i + \bar{e_{i}}) - (\mu + b_j + \bar{e_{j}} ) + (\mu + \bar{e})  \\
&=e_{ij}-\bar{e_i}-\bar{e_j}+\bar{e} \qquad(3.13)

\end{align}
$$
这里面已经毫无$\mu,a_i,b_j$的影响，而只含随机误差。

得到分解式$(3.12)$后，我们就可以像单囚素情况那样，写出下面的方差分析表：
$SS_A , SS_B$ 自由度分别为其水平数减去1，这一点与单因素情况相同．总和自由度为全部观察值数目$kl$减去1．剩下的就是误差平方和自由度：
$$
(kl - 1) - (k - 1) - (l - 1) = (k - 1) (l - 1)
$$
**表3.1 双因素方差分析表**

| 项目 | $SS$   | 自由度            | $MS$   | $F$比         | 显著性      |
| ---- | ------ | ----------------- | ------ | ------------- | ----------- |
| $A$  | $SS_A$ | $k-1$             | $MS_A$ | $MS_A / MS_e$ | *, **, 或无 |
| $B$  | $SS_B$ | $l-1$             | $MS_B$ | $MS_B / MS_e$ |             |
| 误差 | $SS_e$ | $(k - 1) (l - 1)$ | $MS_e$ |               |             |
| 总和 | $SS$   | $kl-1$            |        |               |             |

还有一点要注意：在采纳模型$(3.1)$时，事实上引进了 一 种假定，即两因素$A,B$对指标的效应是可以叠加的．换一种方式说：因素$A$的各水平的优劣比较，与因素$B$处在哪个水平无关，反之亦然．更一般的情况是：$A,B$两因子有“交互作用 ＂ 。这时在模型(5.13)中，还要加上表示交互作用的项$c_{ij}$．这时不仅统计分析复杂化了，尤其是分析结果的解释也复杂化了．本文档暂不讨论这种情况。在一个特定的问题中，交互作用是否需要考虑，在很大程度上取决于问题的实际背景和经验．有时，通过试验数据的分析也可以看出一些问题。例如，若误差方差$\sigma^2$的估计$MS_e $反常地大，则有可能是由于交互作用所致．因为可以证明：若交互作用确实存在而未加考虑，则它的影响进入随机误差而增大了$MS_e$。

### 代码实现

参考：https://blog.csdn.net/qq_38214903/article/details/82938612

```python
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

# 方差分析表
formula = 'Y~ A + B '
anova_results = anova_lm(ols(formula,df).fit())
print(anova_results)

# 使用tukey方法对颜色进行多重比较

from statsmodels.stats.multicomp import pairwise_tukeyhsd
print(pairwise_tukeyhsd(df['Y'], df['A']))
```

